{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from scipy.spatial import distance as dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME = \"frame\"\n",
    "IN = \"C:/Users/DELL/Desktop/frames/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidTracker():\n",
    "    def __init__(self, maxDisappeared=50):\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "\n",
    "    def register(self, centroid):\n",
    "\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "\n",
    "    def update(self, rects):\n",
    "        if len(rects) == 0:\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "\n",
    "            return self.objects\n",
    "\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "        boxMapping = {}\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "            boxMapping[tuple(inputCentroids[i])] = i\n",
    "\n",
    "\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "\n",
    "        else:\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "\n",
    "            rows = D.min(axis=1).argsort()\n",
    "\n",
    "\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "\n",
    "            for (row, col) in zip(rows, cols):\n",
    "\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                for row in unusedRows:\n",
    "\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "\n",
    "\n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "\n",
    "\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    "\n",
    "        return (self.objects, boxMapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_rcnn  = os.path.join('mask-rcnn-coco/')\n",
    "confidence =0.5\n",
    "threshold = 0.3\n",
    "video   = os.path.join('video.mp4')\n",
    "# out  = os.path.join('C:/Users/DELL/Desktop/PFE/seg_action3.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the COCO class labels our Mask R-CNN was trained on\n",
    "labelsPath = os.path.sep.join([mask_rcnn,\"object_detection_classes_coco.txt\"])\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a list of colors to represent each possible class label\n",
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive the paths to the Mask R-CNN weights and model configuration\n",
    "weightsPath = os.path.sep.join([mask_rcnn,\"frozen_inference_graph.pb\"])\n",
    "configPath = os.path.sep.join([mask_rcnn,\"mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Mask R-CNN from disk...\n"
     ]
    }
   ],
   "source": [
    "# load our Mask R-CNN trained on the COCO dataset (90 classes)\n",
    "# from disk\n",
    "print(\"[INFO] loading Mask R-CNN from disk...\")\n",
    "net = cv2.dnn.readNetFromTensorflow(weightsPath, configPath)\n",
    "ct = CentroidTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 475 total frames in video\n"
     ]
    }
   ],
   "source": [
    "vs = cv2.VideoCapture(video)\n",
    "writer = None\n",
    "# try to determine the total number of frames in the video file\n",
    "try:\n",
    "    prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n",
    "        else cv2.CAP_PROP_FRAME_COUNT\n",
    "    total = int(vs.get(prop))\n",
    "    print(\"[INFO] {} total frames in video\".format(total))\n",
    "\n",
    "# an error occurred while trying to determine the total\n",
    "# number of frames in the video file\n",
    "except:\n",
    "    print(\"[INFO] could not determine # of frames in video\")\n",
    "    total = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] single frame took 5.2096 seconds\n",
      "[INFO] estimated total time to finish: 2474.5404\n",
      "[INFO] single frame took 5.2690 seconds\n",
      "[INFO] estimated total time to finish: 2502.7798\n",
      "[INFO] single frame took 5.2005 seconds\n",
      "[INFO] estimated total time to finish: 2470.2348\n",
      "[INFO] single frame took 4.8573 seconds\n",
      "[INFO] estimated total time to finish: 2307.2347\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-55ef894af077>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"detection_out_final\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"detection_masks\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#     frame = np.multiply(frame,0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "poly = []\n",
    "j = 0\n",
    "pixel_person = pd.DataFrame({'frame_Id':[], 'person_id':[],'pixel': [], 'confidence': []})\n",
    "\n",
    "while True:\n",
    "    (grabbed, frame) = vs.read()\n",
    "    if not grabbed:\n",
    "        break\n",
    "    blob = cv2.dnn.blobFromImage(frame, swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    start = time.time()\n",
    "    (boxes, masks) = net.forward([\"detection_out_final\",\"detection_masks\"])\n",
    "    end = time.time()\n",
    "#     frame = np.multiply(frame,0)\n",
    "    rects = []\n",
    "    classIds = []\n",
    "    for i in range(0, boxes.shape[2]):\n",
    "        classID = int(boxes[0, 0, i, 1])\n",
    "        confidence = boxes[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            (H, W) = frame.shape[:2]\n",
    "            box = boxes[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "            rects.append(box.astype(\"int\"))\n",
    "            classIds.append(classID)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "    # track objects found \n",
    "    objects, boxMapping = ct.update(rects)\n",
    "    for (objectID, centroid) in objects.items():\n",
    "        # find the rect and class id of the current object \n",
    "        try :\n",
    "            (startX, startY, endX, endY) = rects[boxMapping[tuple(centroid)]]\n",
    "            classID = classIds[boxMapping[tuple(centroid)]]\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        boxW = endX - startX\n",
    "        boxH = endY - startY\n",
    "        mask = masks[i, classID]\n",
    "        mask = cv2.resize(mask, (boxW, boxH),interpolation=cv2.INTER_NEAREST)\n",
    "        mask = (mask > 0.3)\n",
    "        roi = frame[startY:endY, startX:endX][mask]\n",
    "\n",
    "        text = \"ID {}\".format(objectID)\n",
    "        cv2.putText(frame, text, (centroid[0] - 10, centroid[1] - 10),\n",
    "              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.circle(frame, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
    "#       frames.append(frame)\n",
    "\n",
    "        color = COLORS[objectID] \n",
    "        blended = ((0.4 * color) + (0.6* roi)).astype(\"uint8\")\n",
    "#         blended = ((1*color)+(0*roi)).astype('uint8')\n",
    "        frame[startY:endY, startX:endX][mask] = blended\n",
    "        \n",
    "#         frames.append(frame)\n",
    "        color = [int(c) for c in color]\n",
    "#         cv2.rectangle(frame, (startX, startY), (endX, endY),color, 2)\n",
    "#         text = \"{}: {:.4f}\".format(LABELS[classID], confidence)\n",
    "#         cv2.putText(frame, text, (startX, startY - 5),cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        if LABELS[classID]=='person':\n",
    "            pixel_person = pixel_person.append({'frame_Id':j,'person_id':objectID,\n",
    "                                'pixel': color,\n",
    "                                'confidence':confidence},\n",
    "                                ignore_index=True)\n",
    "\n",
    "            \n",
    "#             pixel_person.append(color)\n",
    "    if total > 0:\n",
    "        elap = (end - start)\n",
    "        print(\"[INFO] single frame took {:.4f} seconds\".format(elap))\n",
    "        print(\"[INFO] estimated total time to finish: {:.4f}\".format(elap * total))\n",
    "    \n",
    "    \n",
    "    \n",
    "    im_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imwrite(\"C:/Users/DELL/Desktop/PFE/instance_segmentation/mask-rcnn/frames/frame%d.jpg\" % j,im_rgb)\n",
    "\n",
    "    cv2.imshow(\"show\", frame)\n",
    "    \n",
    "    j = j+1\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "print(\"[INFO] cleaning up...\")\n",
    "vs.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
